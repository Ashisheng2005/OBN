# OBN

## 基于ospf和gbp的网络数据实现自主决策网络模型

1. 安装第三方库

```bash
pip install -r requirements.txt
```



已经训练好的模型文件

分类模型：

```bash
.\model\best_path_classification_model.weights.h5
```

回归模型：

```bash
.\model\best_path_regression_model.weights.h5
```

回归模型采用R2评分。

模型训练的结果将会保存在./chart目录中，一下是不同数量的训练结果(前者为分类模型，后者为回归模型，共三个数量级测试)：

**100数量级**

![](https://github.com/Ashisheng2005/OBN/blob/main/chart/Classification_100.png)

![](https://github.com/Ashisheng2005/OBN/blob/main/chart/Regression_100.png)

**1000数量级**

![](https://github.com/Ashisheng2005/OBN/blob/main/chart/Classification_1000.png)

![](https://github.com/Ashisheng2005/OBN/blob/main/chart/Regression_1000.png)

**8000数量级**

![Classification_8000](https://github.com/Ashisheng2005/OBN/blob/main/chart/Classification_8000.png)

![](https://github.com/Ashisheng2005/OBN/blob/main/chart/Regression_8000.png)



训练数据通过ospf和bgp结果通过算法模拟生成，如果想要更加接近现实可添加更复杂的数据。

ospf数据存放位置：

```bash
.\data\ospf_data.txt
```

bgp数据存放位置：

```bash
.\data\bgp_data.txt
```

数据示例：

```bash
# BGP Data:
BGP table version is 12, local router ID is 192.168.1.1
Status codes: s suppressed, d damped, h history, * valid, > best, i - internal
Origin codes: i - IGP, e - EGP, ? - incomplete

   Network          Next Hop            Metric LocPrf Weight Path
*> 10.1.1.0/24      192.168.2.2             100    100      0 65001 i
*  10.1.2.0/24      192.168.2.3             200    100      0 65002 65003 i
*> 172.16.1.0/24    192.168.2.4             150    200      0 65004 i
*  10.1.3.0/24      192.168.2.5             120    80       0 65005 65006 65007 i
*> 192.168.3.0/24   192.168.2.6             110    120      0 65008 i
*  10.1.4.0/24      192.168.2.7             130    90       0 65009 65010 i
*> 10.1.5.0/24      192.168.2.8             140    100      0 65001 65002 i
*  172.16.2.0/24    192.168.2.9             160    150      0 65003 i
*> 10.1.6.0/24      192.168.2.10            170    100      0 65004 65005 65006 i
*  10.1.7.0/24      192.168.2.11            180    80       0 65007 i
*> 192.168.4.0/24   192.168.2.12            190    200      0 65008 65009 i
*  10.1.8.0/24      192.168.2.13            200    90       0 65010 i
*> 10.1.9.0/24      192.168.2.14            210    100      0 65001 65002 65003 i
*  172.16.3.0/24    192.168.2.15            220    120      0 65004 i
*> 10.1.10.0/24     192.168.2.16            230    150      0 65005 i

# OSPF Data:
Neighbor ID     Pri   State           Dead Time   Address         Interface
10.0.0.2        1     FULL/DR         00:00:38    192.168.1.2     GigabitEthernet0/0
10.0.0.3        1     FULL/BDR        00:00:35    192.168.1.3     GigabitEthernet0/1
10.0.0.4        1     2WAY/DROTHER    00:00:40    192.168.1.4     GigabitEthernet0/2
10.0.0.5        0     DOWN/-          00:00:00    192.168.1.5     GigabitEthernet0/3
10.0.0.6        1     FULL/DR         00:00:37    192.168.1.6     GigabitEthernet0/4
10.0.0.7        1     FULL/BDR        00:00:36    192.168.1.7     GigabitEthernet0/5
10.0.0.8        1     2WAY/DROTHER    00:00:39    192.168.1.8     GigabitEthernet0/6
10.0.0.9        1     FULL/DR         00:00:38    192.168.1.9     GigabitEthernet0/7
10.0.0.10       0     DOWN/-          00:00:00    192.168.1.10    GigabitEthernet0/8
10.0.0.11       1     FULL/BDR        00:00:35    192.168.1.11    GigabitEthernet0/9
```



## 训练模型

在开始训练模型之前需要进行一些必要的配置，训练模型的文件为

```bash
.\Training_model.py
```



**真实环境获取数据进行训练**

训练中的数据默认全部为模拟数据，如果你需要根据真实数据训练，可以对文件中21行如下设置：

```python
    def main(self):
        training_data = Collect_network_data(mode="real").main()	# 设置mode为真实，默认为虚拟
        ...
```

当设置模式为真实后，会启动脚本自动连接交换机，所以你需要正确配置链接信息：

```json
# ./config.json
"real": {
        "device": [
            {
                "device_type": "cisco_ios",
                "host": "192.168.1.1",
                "username": "admin",
                "password": "password"
            },
            {
                "device_type": "huawei",
                "host": "router2",
                "username": "admin",
                "password": "password"
            }
        ],
    	......
    },

```

device中的每个哈希表都是一台设备的配置，支持多设备批量获取数据。



**虚拟环境通过自定义数据进行训练**

通过向**.\data\ospf_data.txt** 和 **.\data\bgp_data.txt **中添加网络协议数据进行训练，默认提供一些数据。



**调整配置文件**

```json
# ./config.json
...

    "Classification_model": {
        "epochs": 500	# 分类模型训练步数
    },
    "Regression_model": {
        "epochs": 500	# 回归模型训练步数
    },
...
"virtual": {
        "num_samples": 8000		# 虚拟环境生成的数据集大小
    }

```

实际训练中可能跑不到设定的步数，因为模型为了防止过拟合引入了**早停**机制。



配置文件修改完成后即可启动训练文件：

```bash
python Training_model.py
```



复杂环境设置：

模型实习了动态批量大小，根据数据量动态调整batch_size大小（小数据量用小批量，大数据量用大批量）

```python
batch_size = 32 if data_size < 1000 else 64 if data_size < 5000 else 128
```

在训练文件**Training_model.py**中，分类模型和回归模型**都存在各自的语句**，可根据实际需求修改：

# 更新内容



## 2025.4.17

数据问题：

1. 特征集包括了（' as_path_length ', ' local_pref ', ' ospf_state ', ' bandwidth ', ' latency ', ' packet_loss ', ' bandwidth_utilization '），但实际指标远不止这些，可以进行扩展以捕获更多的网络动态，例如：抖动、往返长度（RTT）、路由器的CPU/内存利用率或队列长度等等。

2. 时态特征：可以从上次ospf状态变化或BGP如有更新到现在的时间来捕获网络稳定性。
3. 派生特征：计算路径稳定性（路由振荡频率）或归一化指标（延迟/带宽的比率）等特征来丰富数据集
4. 分类编码：对于分类变量，例如“接口”类型，使用单热编码或目标编码，而不是依赖于模拟带宽值。
5. 在生成的模拟数据中，合成数据可能无法完全代表现实世界的场景，但可以使用统计分布来更现实的模拟拥塞和数据包丢失，或者基于现实网络拓扑模拟数据，以考虑多跳依赖关系和路由循环。而对于数据增强方面，可以引入噪声或者扰动来模拟边缘情况（例如：链路故障，突然流量峰值等）。
6. 对于训练时进行的SMOTE过采样，虽然解决了is_best的类不平衡问题，但也可能引入人工合成痕迹。为解决这个问题，后续我们会通过替代技术尝试其他不平衡处理方法，例如类加权损失函数或对多数类进行欠采样。阈值调整也是一种不错的选择，目前采用固定的is_best阈值的方案并不靠谱，后续会改为使用验证集来动态调整决策边界。汇总方案为将SMOTE于ADASYN或borderline-SMOTE等其他技术相结合，以生成更强大的合成样本。
7. 目前的对于数据有效性的保证是通过基本断言来实现的。但对真实世界的数据没有全面的清理。解决方案一是进行离群检测，通过实现**离群检测**（例如IQR或者孤立森林算法）来过滤’延迟‘、'pack_loss'或'带宽'中的异常值。而对于部分数据可能存在的数据缺失所造成的ospf/bgp数据不完整。后续需要补充额外的缺失值处理函数。对于特征关联分析，可以使用关联矩阵或互信息评分来识别冗余特征，降低维数。

模型架构问题

1. 目前使用的分类模型和回归模型使用三层隐藏层和L2正则化的固定架构，这不是所有数据集的最佳选择。
2. 关于超参数调优问题，后续可以使用自动化工具，例如：Keras Tuner或者Optuna来优化层大小、辍学率、学习率和L2正则化强度。其次，可以通过添加"BatchNormalization" 层来实现稳定训练并提高收敛性，特别是对于更深的网络。而对于较大的数据集，可以通过合并跳过连接以缓解更深层次架构中的梯度消失问题。特别的，对于回归模型，实现自定义损失函数来处理 path_cost 中的异常值。
3. 当前的代码库完全依赖于密集的神经网络，但实际上它可能不像其他模型那样有效地捕获网络数据中的复杂模式。由于网络路由数据本质上是基于图的（路由器作为节点，链路作为边），gnn可以更有效地构建拓扑模型。对于实时预测可以使用rnn或者lstm来捕获路由数据中的时间依赖性。对于较小的数据集，梯度增强模型例如：XGBoost、LightGBM等，通常优于神经网络，，并且计算强度较低。而在最后，可以将神经网络于基于树的模型结合在一起，以利用他们的互补优势。
4. 当前模型使用L2正则化和dropout，但是dropout率相对较高，可能导致欠拟合。为解决该问题，后续可能会使用蒙特卡罗退出的不确定性估计等技术。通过实现L2正则化的衰减调度，以减少其在后期训练阶段的影响。
5. 目前模型使用早停和降低学习率的机制，但训练稳定性可以提高，例如：应用梯度裁剪，以防止爆炸梯度，特别是对于较大的数据集。指定’热身计划‘：使用学习率热身阶段来稳定初始训练。通过实现k-fold 交叉验证，以确保跨不同数据分割的稳健性能。
6. 目前，batch大小和epoch是根据数据大小改动的，但是其他超参数是固定的。对于这种问题会使用网格搜索或者贝叶斯优化来找到学习率，batch大小和层数的最优值。也可以尝试像RMSprop或者AdamW这样的优化器，他们可能会更快的收敛于某些数据集。还有动态的调整epoch数，而不是使用固定的数值。

评价指标问题

1. 当前模型中，分类模型使用精度，回归模型使用MSE、MAE和R²,但这些可能都无法完全捕获模型的性能。而对于这一方面的修改，计划添加进度、召回率，f1得分和ROC-AUC来评估分类模型，特别是对于不平衡的数据集。至于回归模型，添加RMSE或者MAPE等指标，以提供更全面的的回归性能视图。最后是自定义指标，例如：路径选择准确性、平均延迟减少等等，但其根本依然是与网络优化目标保持一致。

部署和可伸缩性问题

1. 虽然在Netmiko中进行设备轮询，但这可能无法扩大到大型网络或频繁更新的环境中，而可以使用异步轮询的方式，使用 asyncio 或 concurrent 在多个设备上并行收集数据。或者集成遥测协议，如gNMI 或 NETCONF实时时间驱动的数据收集，而不是定期轮询。缓存访问频繁的OSPF/BGP数据，减少冗余查询，提高相应速度。
2. start.py 为每个推理加载模型和所放弃，但这对于实时应用程序是低效的，应用训练后量化（如使用TensorFlow Lite）来减少模型大小和推理延迟。或者将模型转换为ONNX格式，以实现更快的推理和跨平台兼容性。start.py后续将支持同时对多条路径进行批处理预测，提高吞吐量。
3. 代码库的框架单一，缺乏模块化部署框架，因为目前只是实验性测试，后续将会采用多种方案进行比对测试例如：微服务，将数据采集、预处理和推理分离到单独的微服务中，以获得更好的可扩展性和故障隔离。Containerization：使用Docker容器化应用程序，确保环境一致，更容易部署。而对于大规模网络，可部署在Kubernetes上，实现大规模网络的负载均衡和自动伸缩。



## 2025.4.13

分类模型问题：

**过拟合**：在小数据集上，模型可能记住训练数据，导致高准确率，但在大数据集上泛化能力下降。

**模型复杂度不足**：如果模型结构较简单（如浅层神经网络），可能无法捕捉大数据集的复杂模式。

**数据质量或分布问题**：大数据集可能引入噪声或类别不平衡，导致准确率下降。

**超参数未优化**：学习率、批量大小、优化器等可能未针对不同数据量和Epoch进行调整。



回归模型问题：

**回归任务的损失函数**：回归模型的“准确率”可能不是最佳评估指标，均方误差（MSE）或平均绝对误差（MAE）可能更能反映模型性能。

**过拟合**：与分类模型类似，小数据集高准确率可能源于过拟合。

**特征选择或预处理不足**：回归任务对特征的缩放和分布敏感，可能需要更强的特征工程。

**模型容量不足**：回归任务可能需要更深的网络或更复杂的模型（如树模型或集成模型）。



解决方法：

**正则化**：在模型中加入Dropout、L2正则化或者Batch Normalization

**早停机制**：监控验证集损失，当验证损失不在下降时停止训练

**数据增强**：增加模拟数据的变化，引入多个网络质量指标，动态模拟网络状态。增加训练数据的多样性，减少过拟合。

**增加模型深度或宽度**：根据训练数据体量动态调配神经网络层和隐藏单元层

**尝试其他模型**：对于分类任务，可以尝试随机森林或XGBoost；对于回归任务，可以尝试梯度提升树。（暂留后续投票机制中使用）

**检查数据分布**：确保训练集和测试集分布一致，检查是否存在类别不平很或异常值

**特征工程**：对回归任务，确保特征标准化，对分类任务，检查特征重要性



